{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SDuc05QCl_N1"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# по API подключаемся к kaggle и скачиваем нужный датасет\n",
        "# для этого в colab надо подгрузить файл kaggle.json, который содержит токен и пароль\n",
        "# после этого в проводнике colab появится папка с данными\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "\n",
        "# username\t\"sergses\" key\t\"e07c32b04e8117da59c5dc5f21ed2087\"\n",
        "od.download( \"https://www.kaggle.com/competitions/what-on-the-video\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeW2-akImaAi",
        "outputId": "84bd555f-0ad1-4373-925b-e0b3b8159d06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: daniillosev\n",
            "Your Kaggle Key: ··········\n",
            "Downloading what-on-the-video.zip to ./what-on-the-video\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 690M/690M [00:03<00:00, 206MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting archive ./what-on-the-video/what-on-the-video.zip to ./what-on-the-video\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "cKB1_zuTYLWM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove('/content/what-on-the-video/train/Humming_Bird_1_preview.mp4')"
      ],
      "metadata": {
        "id": "YpOwC4clXlYs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train:\", len(os.listdir('/content/what-on-the-video/train')))\n",
        "print(\"test:\", len(os.listdir('/content/what-on-the-video/test')))"
      ],
      "metadata": {
        "id": "vQTN4tESsumJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab190df-e814-4936-925a-4e6e296ca6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 427\n",
            "test: 435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/what-on-the-video/train.csv')\n",
        "df['labels'] = df['labels'].apply(lambda x: x.replace('cloud. water', 'cloud, water'))\n",
        "df['labels'] = df['labels'].apply(lambda x: x.split(', '))\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(df['labels'])\n",
        "y = pd.DataFrame(y, columns=mlb.classes_)\n",
        "df = pd.concat([df, y], axis=1)\n",
        "df['labels'] = df['labels'].apply(lambda x: x[0])\n",
        "train_df, val_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df['labels'])\n",
        "train_df = train_df.drop(['labels'], axis=1).reset_index(drop=True)\n",
        "val_df = val_df.drop(['labels'], axis=1).reset_index(drop=True)\n",
        "print(train_df.shape, val_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ys7RRTCX0ND",
        "outputId": "72cc58e8-69f7-4877-e8f6-dbf29c1488dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(246, 10) (44, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/content/what-on-the-video/test'\n",
        "\n",
        "test_df = pd.DataFrame(sorted(os.listdir(test_path)), columns = ['path'])\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "syunJly2YB0S",
        "outputId": "2c61c507-83e3-404f-fc9a-e3e44aff9fd2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  path\n",
              "0    000464896-guatemala-antigua-church-festi_previ...\n",
              "1    000691821-mexico-puerto-vallarta-ocean_preview...\n",
              "2    000692230-panama-canal-clouds-over-gatun_previ...\n",
              "3      000745494-florida-anhinga-dead-tree_preview.mp4\n",
              "4                000764644-sunset-and-boat_preview.mp4\n",
              "..                                                 ...\n",
              "430              myrdalssandur_iceland_one_preview.mp4\n",
              "431                                  reed1_preview.mp4\n",
              "432                          rifugio_becco_preview.mp4\n",
              "433                 rover_and_rocks_medium_preview.mp4\n",
              "434                          water_bubbles_preview.mp4\n",
              "\n",
              "[435 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f42c4ce-171c-4a60-b7b8-d79863e7ba3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000464896-guatemala-antigua-church-festi_previ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000691821-mexico-puerto-vallarta-ocean_preview...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000692230-panama-canal-clouds-over-gatun_previ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000745494-florida-anhinga-dead-tree_preview.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000764644-sunset-and-boat_preview.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>myrdalssandur_iceland_one_preview.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>reed1_preview.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>rifugio_becco_preview.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>rover_and_rocks_medium_preview.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>water_bubbles_preview.mp4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>435 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f42c4ce-171c-4a60-b7b8-d79863e7ba3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f42c4ce-171c-4a60-b7b8-d79863e7ba3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f42c4ce-171c-4a60-b7b8-d79863e7ba3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-030fa848-b8ee-4c94-a7a3-ce3dee41d8a0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-030fa848-b8ee-4c94-a7a3-ce3dee41d8a0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-030fa848-b8ee-4c94-a7a3-ce3dee41d8a0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 435,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 435,\n        \"samples\": [\n          \"Northern Ireland Antrim zooms on tiny tide pool_preview.mp4\",\n          \"171124_I1_004_preview.mp4\",\n          \"190802_17a_HD_21_preview.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, dataframe, video_dir, transform=None, frames_per_clip=64, resize=(128, 128), mode='train'):\n",
        "        self.data = dataframe.reset_index(drop=True)\n",
        "        self.video_dir = video_dir\n",
        "        self.transform = transform\n",
        "        self.frames_per_clip = frames_per_clip\n",
        "        self.resize = resize\n",
        "        self.mode = mode\n",
        "        self.label_columns = ['animal', 'car', 'cloud',\n",
        "                             'dance', 'fire', 'flower',\n",
        "                             'food', 'sunset', 'water']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        video_path = os.path.join(self.video_dir, row['path'])\n",
        "        frames = self.get_uniform_frames(video_path)\n",
        "        tensor_frames = [self.transform(frame) for frame in frames]\n",
        "        video_tensor = torch.stack(tensor_frames)\n",
        "\n",
        "        if self.mode in ['train', 'val']:\n",
        "            label = torch.tensor(row[self.label_columns].values.astype(np.float32))\n",
        "            return video_tensor, label\n",
        "        else:\n",
        "            return video_tensor, row['path']\n",
        "\n",
        "    def get_uniform_frames(self, video_path):\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        step = total_frames / self.frames_per_clip\n",
        "        indices = [int(i * step) for i in range(self.frames_per_clip)]\n",
        "\n",
        "        frames = []\n",
        "        current_idx = 0\n",
        "        target_set = set(indices)\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            if current_idx in target_set:\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame = cv2.resize(frame, self.resize)\n",
        "                frames.append(frame)\n",
        "            current_idx += 1\n",
        "            if len(frames) >= self.frames_per_clip:\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        return frames\n"
      ],
      "metadata": {
        "id": "XPS-1J2C4QWL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.Resize((112, 112)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((112, 112)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = VideoDataset(train_df, \"/content/what-on-the-video/train\", transform=train_transform)\n",
        "val_dataset = VideoDataset(val_df, \"/content/what-on-the-video/train\", transform=test_transform, mode='val')\n",
        "test_dataset = VideoDataset(test_df, \"/content/what-on-the-video/test\", transform=test_transform, mode='test')\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "Ok5Pf4N35Bk2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    print(\"Batch shape:\", images.shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "    print(\"Пример меток:\", labels[:5])\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0IkNSpz44uv",
        "outputId": "def2a701-3a77-4cd5-fe66-8853aa8da645"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([8, 64, 3, 112, 112])\n",
            "Labels shape: torch.Size([8, 9])\n",
            "Пример меток: tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetGRU(nn.Module):\n",
        "    def __init__(self, hidden_dim=256, num_layers=2, num_classes=9, pretrained=True):\n",
        "        super(ResNetGRU, self).__init__()\n",
        "        resnet = models.resnet50(pretrained=pretrained)\n",
        "        modules = list(resnet.children())[:-1]\n",
        "        self.resnet = nn.Sequential(*modules)\n",
        "        self.feature_dim = resnet.fc.in_features\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=self.feature_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C, H, W = x.size()\n",
        "        x = x.view(B * T, C, H, W)\n",
        "        feats = self.resnet(x)\n",
        "        feats = feats.view(B, T, -1)\n",
        "\n",
        "        gru_out, _ = self.gru(feats)\n",
        "        final_hidden = gru_out[:, -1, :]\n",
        "\n",
        "        out = self.classifier(final_hidden)\n",
        "        return out\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNetGRU().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV32vFA1Ni65",
        "outputId": "e5ec9def-1ce6-4d33-ed12-42501d20f7ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 94.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import torch\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device, threshold=0.5):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    for videos, labels in dataloader:\n",
        "        videos = videos.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(videos)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs > threshold).float()\n",
        "\n",
        "        all_labels.append(labels.cpu())\n",
        "        all_preds.append(preds.cpu())\n",
        "\n",
        "    all_labels = torch.cat(all_labels).numpy()\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1\n",
        "\n"
      ],
      "metadata": {
        "id": "qsRv1DQkTZ4-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import torch\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for videos, labels in dataloader:\n",
        "            videos = videos.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(videos)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (probs > threshold).float()\n",
        "\n",
        "            all_labels.append(labels.cpu())\n",
        "            all_preds.append(preds.cpu())\n",
        "\n",
        "    all_labels = torch.cat(all_labels).numpy()\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1\n"
      ],
      "metadata": {
        "id": "kEfcAzvfUSpV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc, train_f1 = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_f1 = validate_epoch(model, val_loader, criterion, device)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} — \"\n",
        "          f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f}, Train F1: {train_f1:.4f} — \"\n",
        "          f\"Val loss: {val_loss:.4f}, Val acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6R2u5yn64S3",
        "outputId": "ced319af-8f59-401b-df37-bf165bf433a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 — Train loss: 0.4331, Train acc: 0.0000, Train F1: 0.0556 — Val loss: 0.3296, Val acc: 0.0000, Val F1: 0.0000\n",
            "Epoch 2/20 — Train loss: 0.2992, Train acc: 0.0041, Train F1: 0.0091 — Val loss: 0.2919, Val acc: 0.0682, Val F1: 0.0838\n",
            "Epoch 3/20 — Train loss: 0.2497, Train acc: 0.2236, Train F1: 0.2333 — Val loss: 0.2766, Val acc: 0.3182, Val F1: 0.2923\n",
            "Epoch 4/20 — Train loss: 0.2015, Train acc: 0.5000, Train F1: 0.4860 — Val loss: 0.2857, Val acc: 0.3636, Val F1: 0.3101\n",
            "Epoch 5/20 — Train loss: 0.1677, Train acc: 0.7033, Train F1: 0.6547 — Val loss: 0.2796, Val acc: 0.3636, Val F1: 0.2810\n",
            "Epoch 6/20 — Train loss: 0.1403, Train acc: 0.7520, Train F1: 0.7141 — Val loss: 0.2901, Val acc: 0.3409, Val F1: 0.2764\n",
            "Epoch 7/20 — Train loss: 0.1126, Train acc: 0.8293, Train F1: 0.8023 — Val loss: 0.2794, Val acc: 0.4318, Val F1: 0.3634\n",
            "Epoch 8/20 — Train loss: 0.1111, Train acc: 0.8049, Train F1: 0.7876 — Val loss: 0.3109, Val acc: 0.3636, Val F1: 0.2792\n",
            "Epoch 9/20 — Train loss: 0.0879, Train acc: 0.8902, Train F1: 0.8377 — Val loss: 0.3089, Val acc: 0.3409, Val F1: 0.3201\n",
            "Epoch 10/20 — Train loss: 0.0795, Train acc: 0.8902, Train F1: 0.8815 — Val loss: 0.2801, Val acc: 0.4773, Val F1: 0.3784\n",
            "Epoch 11/20 — Train loss: 0.0693, Train acc: 0.9187, Train F1: 0.9235 — Val loss: 0.2960, Val acc: 0.4318, Val F1: 0.3584\n",
            "Epoch 12/20 — Train loss: 0.0657, Train acc: 0.9431, Train F1: 0.9633 — Val loss: 0.2917, Val acc: 0.4318, Val F1: 0.4345\n",
            "Epoch 13/20 — Train loss: 0.0571, Train acc: 0.9268, Train F1: 0.9494 — Val loss: 0.3024, Val acc: 0.4318, Val F1: 0.3625\n",
            "Epoch 14/20 — Train loss: 0.0595, Train acc: 0.9187, Train F1: 0.9194 — Val loss: 0.3463, Val acc: 0.4318, Val F1: 0.3441\n",
            "Epoch 15/20 — Train loss: 0.0619, Train acc: 0.9146, Train F1: 0.9573 — Val loss: 0.3553, Val acc: 0.3864, Val F1: 0.3335\n",
            "Epoch 16/20 — Train loss: 0.0724, Train acc: 0.8984, Train F1: 0.9340 — Val loss: 0.3308, Val acc: 0.4091, Val F1: 0.4092\n",
            "Epoch 17/20 — Train loss: 0.0592, Train acc: 0.9309, Train F1: 0.9486 — Val loss: 0.3150, Val acc: 0.3864, Val F1: 0.3409\n",
            "Epoch 18/20 — Train loss: 0.0575, Train acc: 0.9024, Train F1: 0.9294 — Val loss: 0.3538, Val acc: 0.3864, Val F1: 0.3555\n",
            "Epoch 19/20 — Train loss: 0.0605, Train acc: 0.9268, Train F1: 0.9528 — Val loss: 0.3705, Val acc: 0.3636, Val F1: 0.3434\n",
            "Epoch 20/20 — Train loss: 0.0453, Train acc: 0.9512, Train F1: 0.9689 — Val loss: 0.3609, Val acc: 0.3864, Val F1: 0.3698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "idx_to_label = {\n",
        "    0: 'animal', 1: 'car', 2: 'cloud',\n",
        "    3: 'dance', 4: 'fire', 5: 'flower',\n",
        "    6: 'food', 7: 'sunset', 8: 'water'\n",
        "}\n",
        "\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "all_filenames = []\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "with torch.no_grad():\n",
        "    for videos, filenames in test_loader:\n",
        "        videos = videos.to(device)\n",
        "        outputs = model(videos)\n",
        "\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs > threshold).cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "        all_filenames.extend(filenames)\n",
        "\n",
        "all_labels = []\n",
        "for pred, prob in zip(all_preds, all_probs):\n",
        "    labels = [idx_to_label[i] for i, val in enumerate(pred) if val == 1]\n",
        "\n",
        "    if not labels:\n",
        "        max_idx = prob.argmax()\n",
        "        labels = [idx_to_label[max_idx]]\n",
        "\n",
        "    all_labels.append(\", \".join(labels))\n",
        "\n",
        "submission_df = pd.DataFrame({'file_name': all_filenames, 'label': all_labels})\n",
        "submission_df.index.name = 'index'\n",
        "submission_df.to_csv('submission.csv', index=True)\n"
      ],
      "metadata": {
        "id": "a9qhplsB9foQ"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}